{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前情\n",
    "食物品种共有11类：Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles/Pasta, Rice, Seafood, Soup, and Vegetable/Fruit.\n",
    "\n",
    "Training set: 9866张\n",
    "\n",
    "Validation set: 3430张\n",
    "\n",
    "Testing set: 3347张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms #torchvision是pytorch的一个图形库\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image \n",
    "利用 OpenCV (cv2) 讀入照片，並将照片转换成指定的分辨率，转化成数组存放在 numpy array 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(path, label):# label 是0 或 1，1代表需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    # uint8是专门用于存储各种图像的，范围是从0–255\n",
    "    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8) #初始化，\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8) #初始化\n",
    "    # 给文件夹里的图片一个编号，并将编号和图片组合成一个表\n",
    "    for i, file in enumerate(image_dir):\n",
    "        # cv.imread(filename[, flags]) 得到图像的通道和色彩信息，使用默认参数: 8位深度，3通道\n",
    "        # 结果是一个 高度X宽度 的矩阵，里面的元素是一个3维行向量，表示RGB的值\n",
    "        img = cv2.imread(os.path.join(path, file)) #将文件夹位置和图片名拼接起来，得到图片位置\n",
    "        x[i, :, :] = cv2.resize(img,(128, 128)) # 图片分辨率缩放成 128 * 128，然后放入矩阵\n",
    "        if label:\n",
    "            # 训练集图像命名方式为 [类别]_[第几张图片].jpg\n",
    "            y[i] = int(file.split(\"_\")[0]) #图片名分成2个部分，取前面的一个，得到类别作为 y 值\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data......\n",
      "Size of training data = 1000\n",
      "Size of validation data = 500\n",
      "Size of Testing data = 124\n",
      "用时： 6.275790214538574\n"
     ]
    }
   ],
   "source": [
    "# 分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "workspace_dir = 'hw3_data/'\n",
    "start_time = time.time()\n",
    "print(\"Reading data......\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
    "print(\"Size of validation data = {}\".format(len(val_x)))\n",
    "test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
    "print(\"Size of Testing data = {}\".format(len(test_x)))\n",
    "end_time = time.time()\n",
    "print(\"用时：\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 预处理数据\n",
    "在 PyTorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來\"包裝\" data，使後續的 training 及 testing 更為方便。\n",
    "\n",
    "Dataset 需要 overload 兩個函數：__len__ 及 __getitem__\n",
    "\n",
    "__len__ 必須要回傳 dataset 的大小，而 __getitem__ 則定義了當程式利用 [ ] 取值時，dataset 應該要怎麼回傳資料。\n",
    "\n",
    "實際上我們並不會直接使用到這兩個函數，但是使用 DataLoader 在 enumerate Dataset 時會使用到，沒有實做的話會在程式運行階段出現 error。__ getitem __()和__len__() 两个函数必须重写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 来自torchvision.transforms\n",
    "# 训练数据做数据增强 (data augmentation)\n",
    "train_transform = transforms.Compose([ # 处理图片, 用Compose把多个处理步骤整合到一起\n",
    "    transforms.ToPILImage(), #把数据转换为tensfroms格式\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片左右镜像\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] ,这个格式可以直接输入进神经网络了\n",
    "])\n",
    "\n",
    "# 测试数据不需做 数据增强 (data augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 定义ImgDataset类，继承torch.utils.data.Dataset，实现数据读取方式\n",
    "# torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,...) \n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None: #将 y 变成一个长向量 64-bit integer (signed)\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index): #取一张图片和对应的分类 y 值\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None: # 判断是否需要 y 值\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用上面的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_set = ImgDataset(train_x, train_y, train_transform) #训练集\n",
    "val_set = ImgDataset(val_x, val_y, test_transform) #验证集\n",
    "\n",
    "# 使用torch.utils.data.DataLoader(), 实现数据的批量读取\n",
    "#dataset：加载的数据集(Dataset对象); batch_size：batch size; shuffle:：是否将数据打乱\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "**```torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)```**\n",
    "\n",
    "每个“filter”实际上是“卷积核”的一个集合, 每个通道都对应一个卷积核, 且这个卷积核是独一无二的, 每一个通道进行卷积运算,最后相加,形成一个filter 的单通道输出\n",
    "- **in_channels** 每个卷积层中卷积核的数量\n",
    "- **out_channels** 层中filter的个数，每个filter输出一个矩阵\n",
    "- **kernel_size** 卷积核的大小，卷积核是一个二维方阵，只需要指定一维\n",
    "- **步长(Stride)** 滑动filter时，先从输入的左上角开始，每次往左滑动一列或者往下滑动一行逐一计算输出，将每次滑动的行数和列数称为Stride\n",
    "- **填充（Padding）** 用filter扫描图片时，中心的像素会被扫描多次，而图片边缘的像素只会被扫描一次，导致丢失了图片边界处的信息。有时我们还希望输入和输出的大小应该保持一致。为解决这个问题，可以在矩阵的边界上填充一些值，以增加矩阵的大小 \n",
    "<img src=\"hw3_data/pading.gif\" width=\"20%\"> \n",
    "\n",
    "---\n",
    "\n",
    "**```torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)```**\n",
    "\n",
    "批标准化(Batch Normalization)操作:\n",
    "- 先对输入进行归一化，$\\bar X$为均值，Var(x)为方差, eps 防止分母为 0\n",
    "- 然后对归一化的结果进行缩放和平移，设置affine=True，即意味着缩放(γ)和平移(β)将被使用\n",
    "- momentum：动态均值和动态方差所使用的动量 $ x_{new} = (1 - momentum)\\times x + momentum \\times x_t $ 其中：x是估计的数据 $x_t$是新的观察到的数据\n",
    "- 默认情况下 $ \\gamma =1, bias = 0, momentum = 0.1, eps = 10^{-5} $\n",
    "- num_features: 输入的层数\n",
    "$$ y = {{x-\\bar X} \\over {\\sqrt {var(X)+eps}}} \\times \\gamma + bias $$\n",
    "\n",
    "---\n",
    "\n",
    "**```torch.nn.MaxPool2d(kernel_size, stride, padding)```**\n",
    "\n",
    "- **kernel_size** max pooling的窗口大小\n",
    "- **stride** max pooling的窗口移动的步长，默认值是kernel_size\n",
    "- **padding** 输入的每一条边补充0的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self): # input 維度 [3, 128, 128]\n",
    "        super(Classifier, self).__init__() # super() 初始化父类 nn.Module 的属性,避免直接使用父类的名字\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 这层有64个filter\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), # [in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1] 输出[64, 128, 128]\n",
    "            nn.BatchNorm2d(64), #64 层输入\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # 一张图片用[64, 64, 64]矩阵表示\n",
    "            \n",
    "            # 这层有128个filter\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            # 这层有256个filter\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            # 这层有512个filter\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            # 这层有512个filter\n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            # 一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行\n",
    "            # 以神经网络模块为元素的有序字典也可以作为传入参数。\n",
    "            nn.Linear(512*4*4, 1024), #第1层，有 1024 个 neuron，输入 512*4*4 个feature, 输出 1024 维结果\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512), # 第2层，有 512 个 neuron，输入 1024 个feature, 输出 512 维结果\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11) # 第3层，有 11 个 neuron，输入 512 个feature, 输出 11 维结果，最后一层不需要添加激活函数\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1) # 摊平成1维\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "助教写的model，叠很多层时用这种写法\n",
    "``` python\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Classifier, self).__init__()\n",
    "\n",
    "    def building_block(indim, outdim):\n",
    "      return [ nn.Conv2d(indim, outdim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(outdim),\n",
    "            nn.ReLU(),\n",
    "      ]\n",
    "    def stack_blocks(indim, outdim, block_num):\n",
    "      layers = building_block(indim, outdim)\n",
    "      for i in range(block_num - 1):\n",
    "        layers += building_block(outdim, outdim)\n",
    "      layers.append(nn.MaxPool2d(2, 2, 0))\n",
    "      return layers\n",
    "\n",
    "    cnn_list = []\n",
    "    cnn_list += stack_blocks(3, 128, 3)\n",
    "    cnn_list += stack_blocks(128, 128, 3)\n",
    "    cnn_list += stack_blocks(128, 256, 3)\n",
    "    cnn_list += stack_blocks(256, 512, 1)\n",
    "    cnn_list += stack_blocks(512, 512, 1)\n",
    "    self.cnn = nn.Sequential( * cnn_list)\n",
    "\n",
    "    dnn_list = [\n",
    "      nn.Linear(512 * 4 * 4, 1024),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(p = 0.3),\n",
    "      nn.Linear(1024, 11),\n",
    "    ]\n",
    "    self.fc = nn.Sequential( * dnn_list)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.cnn(x)\n",
    "    out = out.reshape(out.size()[0], -1)\n",
    "    return self.fc(out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "使用 training set 訓練，並使用 validation set 尋找好的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 6.00 GiB total capacity; 4.58 GiB already allocated; 92.50 MiB free; 4.58 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2a018ce3f45b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 给train_loader的矩阵一个编号，并组合成一个表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 用 optimizer 將 model 參數的 gradient 歸零\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用 model 算出来的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用 back propagation 算出每個參數的 gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-442f639d072e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 摊平成1维\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[0;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                             self.return_indices)\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     return torch.max_pool2d(\n\u001b[0m\u001b[0;32m    586\u001b[0m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 6.00 GiB total capacity; 4.58 GiB already allocated; 92.50 MiB free; 4.58 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# 初始化\n",
    "model = Classifier().cuda() # model是Classifier()类\n",
    "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # optimizer 使用 Adam优化算法 RMSProp(移动窗口) + Momentum（惯性）\n",
    "num_epoch = 30\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(train_loader): # 给train_loader的矩阵一个编号，并组合成一个表\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        train_pred = model(data[0].cuda()) # 利用 model 算出来的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval() # 不启用 BatchNormalization 和 Dropout 训练完train样本后，生成的模型model用来测试样本\n",
    "    with torch.no_grad(): #torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到好的參數後，我們使用 training set 和 validation set 共同訓練（資料量變多，模型效果較好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_x = np.concatenate((train_x, val_x), axis=0)\n",
    "train_val_y = np.concatenate((train_y, val_y), axis=0)\n",
    "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n",
    "train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 和上面一样，省略验证部分\n",
    "model_best = Classifier().cuda()\n",
    "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "optimizer = torch.optim.Adam(model_best.parameters(), lr=0.001) # optimizer 使用 Adam\n",
    "num_epoch = 30\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    model_best.train()\n",
    "    for i, data in enumerate(train_val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model_best(data[0].cuda())\n",
    "        batch_loss = loss(train_pred, data[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        #將結果 print 出來\n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n",
    "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的完整模型\n",
    "torch.save(model_best, 'hw3_data/CNN_all.pth')\n",
    "# 保存训练好的完整模型\n",
    "torch.save(model_best.state_dict(), 'CNN_parameter_only.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "利用剛剛 train 好的 model 進行 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImgDataset(test_x, transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        test_pred = model_best(data.cuda())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['面包', '奶', '甜品', '蛋', '油炸食品', '肉', '面条', '米饭', '海鲜', '汤', '果蔬']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將結果寫入 csv 檔\n",
    "with open(\"hw3_data/预测.csv\", 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i, y in  enumerate(prediction):\n",
    "        f.write('{},{},{}\\n'.format(i, y, name[y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重命名测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取该目录下所有文件，存入列表中\n",
    "def rename():\n",
    "    f = os.listdir(\"hw3_data/testing_prediction\")\n",
    "    for i in range(len(f)):\n",
    "        oldname = f[i]\n",
    "        newname = oldname.split(\".\")[0] + '-'+ name[prediction[i]] + '.jpg'\n",
    "        # 用os模块中的rename方法对文件改名\n",
    "        os.rename(\"hw3_data/testing_prediction/\" + oldname, \"hw3_data/testing_prediction/\" + newname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
