{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前情\n",
    "HW7的任務是模型壓縮 - Neural Network Compression。\n",
    "\n",
    "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n",
    "\n",
    "- 知識蒸餾 Knowledge Distillation\n",
    "- 網路剪枝 Network Pruning\n",
    "- 用少量參數來做CNN Architecture Design\n",
    "-* 參數量化 Weight Quantization\n",
    "\n",
    "在這個notebook中我們會介紹非常簡單的Weight Quantization，而我們有提供已經做完Knowledge Distillation的小model來做Quantization。\n",
    "\n",
    "- Model架構 / Architecute Design在同目錄中的hw7_Architecture_Design.ipynb。\n",
    " - 參數為 base=16, width_mult=1 (default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Quantization\n",
    "<img src=\"hw7_data/Weight Quantization.png\" width=\"500px\">\n",
    "\n",
    "我們這邊會示範如何實作第一條: Using less bits to represent a value。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 好的Quantization很重要。\n",
    "\n",
    "|bit|state_dict size|accuracy|\n",
    "|-|-|-|\n",
    "|32|1047430 Bytes|0.81315|\n",
    "|16|522958 Bytes|0.81347|\n",
    "|8|268472 Bytes|0.80791|\n",
    "|7|268472 Bytes|0.80791|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte Cost\n",
    "根據[torch的官方手冊](https://pytorch.org/docs/stable/tensors.html)，我們知道 torch.FloatTensor 預設是 32-bit，也就是佔了 4byte 的空間，而 FloatTensor 系列最低可以容忍的是 16-bit。\n",
    "\n",
    "為了方便操作，我們之後會將 state_dict 轉成 numpy array，因此我們可以先看看 numpy 有甚麼樣的 type 可以使用。\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|16|half precision float| 符号 bit + 5 bits 指数 + 10 bits 尾数|\n",
    "|32|singal precision float| 符号 bit + 8 bits 指数 + 23 bits 尾数|\n",
    "|64|double precision float| 符号 bit + 11 bits 指数 + 52 bits 尾数|\n",
    "\n",
    "而我們發現 numpy 最低有 float16 可以使用，因此我們可以直接靠轉型將 32-bit 的 tensor 轉換成 16-bit 的 ndarray 存起來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read state_dict\n",
    "\n",
    "下載我們已經train好的小model的state_dict進行測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original cost: 1047430 bytes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "path = \"hw7_data/\"\n",
    "\n",
    "print(f\"\\noriginal cost: {os.stat(path + 'student_custom_small.bin').st_size} bytes.\")\n",
    "params = torch.load(path + 'student_custom_small.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32-bit Tensor -> 16-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16-bit cost: 521550 bytes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def encode16(params, file_name): # 將 params 壓縮成 16-bit 後輸出到 file_name\n",
    "    custom_dict = {}\n",
    "    for (name, param) in params.items():\n",
    "        param = np.float64(param.cpu().numpy())\n",
    "        if type(param) == np.ndarray: # 有些東西不屬於ndarray，只是一個數字，這個時候我們就不用壓縮。\n",
    "            custom_dict[name] = np.float16(param)\n",
    "        else:\n",
    "            custom_dict[name] = param\n",
    "\n",
    "    pickle.dump(custom_dict, open(file_name, 'wb'))\n",
    "\n",
    "\n",
    "def decode16(file_name): # 從 file_name 讀取各個 params，將其從 16-bit 還原回 torch.tensor 後存進 state_dict 內\n",
    "    params = pickle.load(open(file_name, 'rb'))\n",
    "    custom_dict = {}\n",
    "    for (name, param) in params.items():\n",
    "        param = torch.tensor(param)\n",
    "        custom_dict[name] = param\n",
    "\n",
    "    return custom_dict\n",
    "\n",
    "\n",
    "encode16(params, path + '16_bit_model.pkl')\n",
    "print(f\"16-bit cost: {os.stat(path + '16_bit_model.pkl').st_size} bytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
