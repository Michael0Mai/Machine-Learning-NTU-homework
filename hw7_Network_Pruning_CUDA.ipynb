{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前情\n",
    "HW7的任務是模型壓縮 - Neural Network Compression\n",
    "\n",
    "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n",
    "* 知識蒸餾 Knowledge Distillation\n",
    "* 網路剪枝 Network Pruning\n",
    "* 用少量參數來做 CNN Architecture Design\n",
    "* 參數量化 Weight Quantization\n",
    "\n",
    "在這個 notebook 中我們會介紹 Network Pruning，而我們有提供已經做完 Knowledge Distillation 的小 model 來做 Pruning。\n",
    "\n",
    "* Model架構 / Architecute Design在同目錄中的hw7_Architecture_Design.ipynb。\n",
    "  * 參數為 base=16, width_mult=1 (default)\n",
    "\n",
    "本次的 model 要求必须将图片直接读入，否则准确率下降到老师例子的一半，非常耗费内存，只能减少训练 dataset 到原来的 10%，但由于是在原有model基础上继续训练，精度下降非常小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Pruning\n",
    "将一個已經學完的 model 中的 neuron 進行刪減，讓整個網路變得更瘦。\n",
    "<img src=\"hw7_data/Neuron Pruning.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight & Neuron Pruning\n",
    "- **neuron pruning**： prune 掉一個 neuron 就等於是把一個 matrix 的整個 column 全部砍掉，matrix 整體變小，运行速度就會比較快\n",
    "- **weight pruning**： matrix大小不變，只是有很多 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to Prune?\n",
    "- 先衡量 Neuron 的重要性，衡量完所有的 Neuron 後，就可以把比較不重要的 Neuron 刪減掉。\n",
    "- 在這裡我們介紹一個很簡單可以衡量 Neuron 重要性的方法 - 就是看batchnorm layer的$\\gamma$因子來決定neuron的重要性。 (by paper - Network Slimming)\n",
    " - $\\bar X$为均值，Var(x)为方差, eps 防止分母为 0， γ 和β是学习得到的\n",
    "$$ y = {{x-\\bar X} \\over {\\sqrt {Var(X)+ eps}}} \\times \\gamma + bias $$\n",
    " - 相信大家看這個pytorch提供的batchnorm公式應該就可以意識到為甚麼$\\gamma$可以當作重要性來衡量了:)\n",
    "\n",
    "- Network Slimming其實步驟沒有這麼簡單，有興趣的同學可以check以下連結。[Netowrk Slimming](https://arxiv.org/abs/1708.06519)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為甚麼這會 work?\n",
    "- 樹多必有枯枝，有些 neuron 只是在躺分，所以有他沒他沒有差\n",
    "- 困難的說可以回想起老師說過的大樂透假說(The Lottery Ticket Hypothesis)就可以知道了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要怎麼實作?\n",
    "- 為了避免複雜的操作，我們會將 StudentNet(width_mult = $\\alpha$)的 neuron 經過篩選後移植到 StudentNet(width_mult=$\\beta$)。($\\alpha  >  \\beta$)\n",
    "- 篩選的方法也很簡單，只需要抓出每一個 block的 batchnorm 的 $\\gamma$ 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些實作細節\n",
    "- 假設model中間兩層是這樣的:\n",
    "\n",
    "|Layer|Output # of Channels|\n",
    "|-|-|\n",
    "|Input|in_chs|\n",
    "|Depthwise(in_chs)|in_chs|\n",
    "|BatchNorm(in_chs)|in_chs|\n",
    "|Pointwise(in_chs, **mid_chs**)|**mid_chs**|\n",
    "|**Depthwise(mid_chs)**|**mid_chs**|\n",
    "|**BatchNorm(mid_chs)**|**mid_chs**|\n",
    "|Pointwise(**mid_chs**, out_chs)|out_chs|\n",
    "\n",
    "則你會發現利用第二個 BatchNorm 來做篩選的時候，跟他的 Neuron 有直接關係的是該層的 Depthwise & Pointwise 以及上層的 Pointwise。\n",
    "因此再做 neuron 篩選時記得要將這四個(包括自己, bn)也要同時 prune 掉。\n",
    "\n",
    "- 在 Design Architecure 內，model 的一個 block，名稱所對應的 Weight；\n",
    "\n",
    "|#|name|meaning|code|weight shape|\n",
    "|-|-|-|-|-|\n",
    "|0|cnn.{i}.0|Depthwise Convolution Layer|nn.Conv2d(x, x, 3, 1, 1, group=x)|(x, 1, 3, 3)|\n",
    "|1|cnn.{i}.1|Batch Normalization|nn.BatchNorm2d(x)|(x)|\n",
    "|2||ReLU6|nn.ReLU6||\n",
    "|3|cnn.{i}.3|Pointwise Convolution Layer|nn.Conv2d(x, y, 1),|(y, x, 1, 1)|\n",
    "|4||MaxPooling|nn.MaxPool2d(2, 2, 0)||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_slimming(old_model, new_model):\n",
    "    params = old_model.state_dict()\n",
    "    new_params = new_model.state_dict()\n",
    "    selected_idx = [] # selected_idx: 每一層所選擇的 neuron 序号\n",
    "    \n",
    "    for i in range(8): # 我們總共有7層CNN，因此逐一抓取選擇的 neuron index 們。\n",
    "        importance = params[f'cnn.{i}.1.weight'] # 根據上表，Batch Normalization 层表示参数的重要性，要抓的 gamma 係數在 cnn.{i}.1.weight 內\n",
    "        old_dim = len(importance) # Batch Normalization 层總共有幾個 neuron\n",
    "        new_dim = len(new_params[f'cnn.{i}.1.weight']) # 每次剪枝的比例不同，一层總共有幾個 neuron\n",
    "        ranking = torch.argsort(importance, descending = True) # 以 Ranking 做 Index 排序，較大的在前面\n",
    "        selected_idx.append(ranking[ : new_dim]) # 把篩選結果放入selected_idx中\n",
    "\n",
    "    now_processed = 1 # 记录处理到哪一层，第 0 层不prune，从第 1 层开始处理\n",
    "    for (name, p1), (name2, p2) in zip(params.items(), new_params.items()):\n",
    "        if name.startswith('cnn') and p1.size() != torch.Size([]) and now_processed != len(selected_idx): # 如果是cnn層 & 參數 > 0個數字 & 不是最后一层則移植參數\n",
    "            if name.startswith(f'cnn.{now_processed}.3'): # 每层的第三步都是 Pointwise，表示該層的移植已經完成，讓 now_processed + 1\n",
    "                now_processed += 1\n",
    "            if name.endswith('3.weight'): # pointwise 的 weight 會被上一層的 pruning 和下一層的 pruning 所影響，因此需要特判\n",
    "                if len(selected_idx) == now_processed: # 如果是最後一層cnn，則輸出的 neuron 不需要prune掉\n",
    "                    new_params[name] = p1[:, selected_idx[now_processed - 1]] # selected_idx[now_processed - 1] 是一个filter\n",
    "                else: # 反之，就依照上層和下層所選擇的index進行移植\n",
    "                    new_params[name] = p1[selected_idx[now_processed]][:, selected_idx[now_processed - 1]] # Conv2d(x,y,1)的weight shape是(y,x,1,1)，順序是反的\n",
    "            else: # 如果不是 pointwise，直接複製\n",
    "                new_params[name] = p1[selected_idx[now_processed]]\n",
    "        else: # 如果是FC層，或是該參數只有一個數字(例如 batchnorm 的 tracenum 等等資訊)，那麼就直接複製\n",
    "            new_params[name] = p1\n",
    "\n",
    "    # 讓新model load進被我們篩選過的parameters，並回傳new_model。        \n",
    "    new_model.load_state_dict(new_params)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "我們的 Dataset 使用的是跟 hw3 - CNN 同樣的 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image \n",
    "本次的 model 必须将图片直接读入，否则准确率下降到老师例子的一半，非常耗费内存，只能减少训练规模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Size of training data = 1000\n",
      "Size of validation data = 500\n",
      "Size of Testing data = 124\n",
      "用时： 6.789473056793213\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def readfile(path, label):# label 是0 或 1，1代表需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    # uint8是专门用于存储各种图像的，范围是从0–255\n",
    "    x = [] #初始化，\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8) #初始化\n",
    "    # 给文件夹里的图片一个编号，并将编号和图片组合成一个表\n",
    "    for i, file in enumerate(image_dir):\n",
    "        image = Image.open(path + \"/\" + file)\n",
    "        image_fp = image.fp # Get File Descriptor\n",
    "        image.load()\n",
    "        image_fp.close() # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "        x.append(image)\n",
    "        if label:\n",
    "            # 训练集图像命名方式为 [类别]_[第几张图片].jpg\n",
    "            y[i] = int(file.split(\"_\")[0]) #图片名分成2个部分，取前面的一个，得到类别作为 y 值\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "# 分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "workspace_dir = 'hw7_data/'\n",
    "start_time = time.time()\n",
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
    "print(\"Size of validation data = {}\".format(len(val_x)))\n",
    "test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
    "print(\"Size of Testing data = {}\".format(len(test_x)))\n",
    "end_time = time.time()\n",
    "print(\"用时：\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 来自torchvision.transforms\n",
    "# 训练数据做数据增强 (data augmentation)\n",
    "train_transform = transforms.Compose([ # 处理图片, 用Compose把多个处理步骤整合到一起\n",
    "    #transforms.ToPILImage(), #把数据转换为tensfroms格式\n",
    "    transforms.RandomCrop(256, pad_if_needed = True, padding_mode='symmetric'), # 随机裁剪到256*256\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片左右镜像\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] ,这个格式可以直接输入进神经网络了\n",
    "])\n",
    "\n",
    "# 测试数据不需做 数据增强 (data augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),   \n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 定义ImgDataset类，继承torch.utils.data.Dataset，实现数据读取方式\n",
    "# torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,...) \n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None: #将 y 变成一个长向量 64-bit integer (signed)\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index): #取一张图片和对应的分类 y 值\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None: # 判断是否需要 y 值\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "train_set = ImgDataset(train_x, train_y, train_transform) #训练集\n",
    "val_set = ImgDataset(val_x, val_y, test_transform) #验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 使用torch.utils.data.DataLoader(), 实现数据的批量读取\n",
    "#dataset：加载的数据集(Dataset对象); batch_size：batch size; shuffle:：是否将数据打乱\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型\n",
    "载入提供的模型，设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw7_data import hw7_Architecture_Design as Architecture_Design\n",
    "\n",
    "net = Architecture_Design.StudentNet()\n",
    "net.load_state_dict(torch.load('hw7_data/student_custom_small.bin'))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training\n",
    "\n",
    "- 每次Prune rate是0.95(每层删去 5% 的filter)，Prune 完後會重新 fine-tune 3 epochs。\n",
    "- 其餘的步驟與你在做hw3 - CNN的時候一樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩余 95.0000% filter, 第 1轮 : [train loss: 0.0193, acc: 0.8490] [valid loss: 0.0426, acc: 0.7780], 用时：5.31 sec(s)\n",
      "剩余 95.0000% filter, 第 2轮 : [train loss: 0.0179, acc: 0.8700] [valid loss: 0.0432, acc: 0.7760], 用时：4.31 sec(s)\n",
      "剩余 95.0000% filter, 第 3轮 : [train loss: 0.0164, acc: 0.8630] [valid loss: 0.0429, acc: 0.7780], 用时：4.32 sec(s)\n",
      "剩余 95.0000% filter, 第 4轮 : [train loss: 0.0182, acc: 0.8470] [valid loss: 0.0425, acc: 0.7680], 用时：4.36 sec(s)\n",
      "剩余 95.0000% filter, 第 5轮 : [train loss: 0.0156, acc: 0.8650] [valid loss: 0.0422, acc: 0.7800], 用时：4.38 sec(s)\n",
      "剩余 90.2500% filter, 第 1轮 : [train loss: 0.0215, acc: 0.8310] [valid loss: 0.0444, acc: 0.7700], 用时：4.57 sec(s)\n",
      "剩余 90.2500% filter, 第 2轮 : [train loss: 0.0222, acc: 0.8270] [valid loss: 0.0468, acc: 0.7600], 用时：4.53 sec(s)\n",
      "剩余 90.2500% filter, 第 3轮 : [train loss: 0.0219, acc: 0.8320] [valid loss: 0.0435, acc: 0.7720], 用时：4.54 sec(s)\n",
      "剩余 90.2500% filter, 第 4轮 : [train loss: 0.0219, acc: 0.8320] [valid loss: 0.0434, acc: 0.7620], 用时：4.61 sec(s)\n",
      "剩余 90.2500% filter, 第 5轮 : [train loss: 0.0195, acc: 0.8300] [valid loss: 0.0442, acc: 0.7720], 用时：4.56 sec(s)\n",
      "剩余 85.7375% filter, 第 1轮 : [train loss: 0.0224, acc: 0.8080] [valid loss: 0.0420, acc: 0.7300], 用时：4.59 sec(s)\n",
      "剩余 85.7375% filter, 第 2轮 : [train loss: 0.0242, acc: 0.7980] [valid loss: 0.0419, acc: 0.7500], 用时：4.63 sec(s)\n",
      "剩余 85.7375% filter, 第 3轮 : [train loss: 0.0236, acc: 0.8200] [valid loss: 0.0423, acc: 0.7520], 用时：4.53 sec(s)\n",
      "剩余 85.7375% filter, 第 4轮 : [train loss: 0.0230, acc: 0.8170] [valid loss: 0.0421, acc: 0.7520], 用时：4.49 sec(s)\n",
      "剩余 85.7375% filter, 第 5轮 : [train loss: 0.0243, acc: 0.8010] [valid loss: 0.0435, acc: 0.7400], 用时：4.52 sec(s)\n",
      "剩余 81.4506% filter, 第 1轮 : [train loss: 0.0258, acc: 0.7910] [valid loss: 0.0442, acc: 0.7300], 用时：4.49 sec(s)\n",
      "剩余 81.4506% filter, 第 2轮 : [train loss: 0.0266, acc: 0.7870] [valid loss: 0.0454, acc: 0.7260], 用时：4.57 sec(s)\n",
      "剩余 81.4506% filter, 第 3轮 : [train loss: 0.0261, acc: 0.7730] [valid loss: 0.0450, acc: 0.7280], 用时：4.50 sec(s)\n",
      "剩余 81.4506% filter, 第 4轮 : [train loss: 0.0267, acc: 0.7790] [valid loss: 0.0454, acc: 0.7200], 用时：4.48 sec(s)\n",
      "剩余 81.4506% filter, 第 5轮 : [train loss: 0.0242, acc: 0.7970] [valid loss: 0.0454, acc: 0.7240], 用时：4.49 sec(s)\n",
      "剩余 77.3781% filter, 第 1轮 : [train loss: 0.0295, acc: 0.7510] [valid loss: 0.0528, acc: 0.7060], 用时：4.52 sec(s)\n",
      "剩余 77.3781% filter, 第 2轮 : [train loss: 0.0285, acc: 0.7540] [valid loss: 0.0530, acc: 0.7080], 用时：4.47 sec(s)\n",
      "剩余 77.3781% filter, 第 3轮 : [train loss: 0.0306, acc: 0.7410] [valid loss: 0.0551, acc: 0.6960], 用时：4.52 sec(s)\n",
      "剩余 77.3781% filter, 第 4轮 : [train loss: 0.0308, acc: 0.7350] [valid loss: 0.0544, acc: 0.6920], 用时：4.50 sec(s)\n",
      "剩余 77.3781% filter, 第 5轮 : [train loss: 0.0323, acc: 0.7630] [valid loss: 0.0548, acc: 0.6940], 用时：4.51 sec(s)\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(train_loader):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    for i, data in enumerate(train_loader): # 给train_loader的矩阵一个编号，并组合成一个表\n",
    "        optimizer.zero_grad() # 將 model 參數的 gradient 歸零\n",
    "        train_pred = net(data[0].cuda()) # 利用 model 算出来的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        \n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    return train_loss/train_set.__len__(), train_acc/train_set.__len__()\n",
    "\n",
    "def val_epoch(val_loader):\n",
    "    val_acc, val_loss = 0 ,0\n",
    "    with torch.no_grad(): #torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = net(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "    return val_loss/val_set.__len__(), val_acc/val_set.__len__()\n",
    "\n",
    "now_width_mult = 1\n",
    "for i in range(5): # prune N 次\n",
    "    now_width_mult *= 0.95 \n",
    "    new_net = Architecture_Design.StudentNet(width_mult = now_width_mult).cuda()\n",
    "    params = net.state_dict()\n",
    "    net = network_slimming(net, new_net)\n",
    "    now_best_acc = 0\n",
    "    for epoch in range(5): #每 prune 一次训练 5 轮，选出最好的一轮\n",
    "        epoch_start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss, train_acc = train_epoch(train_loader)\n",
    "        net.eval()\n",
    "        valid_loss, valid_acc = val_epoch(val_loader)\n",
    "        # 在每個width_mult的情況下，存下最好的model。\n",
    "        if valid_acc > now_best_acc:\n",
    "            now_best_acc = valid_acc\n",
    "            torch.save(net.state_dict(), f'hw7_data/custom_small_rate_{now_width_mult}.bin')\n",
    "        print('剩余 {:6.4f}% filter, 第{:>2d}轮 : [train loss: {:6.4f}, acc: {:6.4f}] [valid loss: {:6.4f}, acc: {:6.4f}], 用时：{:4.2f} sec(s)'.format(\n",
    "            now_width_mult*100, epoch+1, train_loss, train_acc, valid_loss, valid_acc, time.time()-epoch_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImgDataset(test_x, transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False)\n",
    "name = ['面包', '奶', '甜品', '蛋', '油炸食品', '肉', '面条', '米饭', '海鲜', '汤', '果蔬']\n",
    "prediction = []\n",
    "\n",
    "new_net = Architecture_Design.StudentNet(width_mult = 0.95**5).cuda()\n",
    "new_net.load_state_dict(torch.load('hw7_data/custom_small_rate_0.7737809374999999.bin'))\n",
    "new_net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        test_pred = new_net(data.cuda())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)\n",
    "        \n",
    "def rename_and_write_csv():\n",
    "    f = os.listdir(\"hw7_data/testing_prediction\")\n",
    "    for i in range(len(f)):\n",
    "        oldname = f[i]\n",
    "        newname = oldname.split(\".\")[0] + '-'+ name[prediction[i]] + '.jpg'\n",
    "        # 用os模块中的rename方法对文件改名\n",
    "        os.rename(\"hw7_data/testing_prediction/\" + oldname, \"hw7_data/testing_prediction/\" + newname)\n",
    "    \n",
    "    #將結果寫入 csv 檔\n",
    "    with open(\"hw7_data/预测.csv\", 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        for i, y in  enumerate(prediction):\n",
    "            f.write('{},{},{}\\n'.format(i, y, name[y]))\n",
    "        \n",
    "#rename_and_write_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
