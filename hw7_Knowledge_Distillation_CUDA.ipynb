{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前情\n",
    "HW7的任務是模型壓縮 - Neural Network Compression\n",
    "\n",
    "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n",
    "\n",
    "- 知識蒸餾 Knowledge Distillation\n",
    "- 網路剪枝 Network Pruning\n",
    "- 用少量參數來做CNN Architecture Design\n",
    "- 參數量化 Weight Quantization\n",
    "\n",
    "在這個notebook中我們會介紹Knowledge Distillation，\n",
    "而我們有提供已經學習好的大model方便大家做Knowledge Distillation。\n",
    "而我們使用的小model是\"Architecture Design\"過的model。\n",
    "\n",
    "- Architecute Design在同目錄中的hw7_Architecture_Design.ipynb。\n",
    "- 下載pretrained大model(47.2M): https://drive.google.com/file/d/1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN/view?usp=sharing\n",
    "  - 請使用torchvision提供的ResNet18，把num_classes改成11後load進去即可。(後面有範例。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from hw7_data import hw7_Architecture_Design as Architecture_Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation\n",
    "<img src=\"hw7_data/Knowledge Distillation.png\" width = 50%>\n",
    "讓小 model 模仿已經做得很好的大model們，利用大model預測的logits給小model當作標準"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為甚麼這會work?\n",
    "- 例如當 data 不是很乾淨的時候，對一般的 model 來說他是個 noise，只會干擾學習。透過去學習其他大 model 預測的 logits 會比較好。\n",
    "- label 和 label 之間可能有關連，這可以引導小 model 去學習。例如數字 8 可能就和 6, 9, 0 有關係。\n",
    "- 弱化已經學習不錯的 target(?)，避免讓其 gradient 干擾其他還沒學好的 task。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要怎麼實作?\n",
    "$$Loss = \\alpha T^2 \\times KL(\\frac{\\text{Teacher's Logits}}{T} || \\frac{\\text{Student's Logits}}{T}) + (1-\\alpha)(\\text{Original Loss})$$\n",
    "\n",
    "\n",
    "- 以下code為甚麼要對student使用log_softmax: https://github.com/peterliht/knowledge-distillation-pytorch/issues/2\n",
    "- reference: [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "我們的 Dataset 使用的是跟 hw3 - CNN 同樣的 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image \n",
    "本次的 model 必须将图片直接读入，否则准确率下降到老师例子的一半，非常耗费内存，只能减少训练规模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Size of training data = 1000\n",
      "Size of validation data = 500\n",
      "Size of Testing data = 124\n",
      "用时： 7.232342720031738\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def readfile(path, label):# label 是0 或 1，1代表需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    # uint8是专门用于存储各种图像的，范围是从0–255\n",
    "    x = [] #初始化，\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8) #初始化\n",
    "    # 给文件夹里的图片一个编号，并将编号和图片组合成一个表\n",
    "    for i, file in enumerate(image_dir):\n",
    "        image = Image.open(path + \"/\" + file)\n",
    "        image_fp = image.fp # Get File Descriptor\n",
    "        image.load()\n",
    "        image_fp.close() # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "        x.append(image)\n",
    "        if label:\n",
    "            # 训练集图像命名方式为 [类别]_[第几张图片].jpg\n",
    "            y[i] = int(file.split(\"_\")[0]) #图片名分成2个部分，取前面的一个，得到类别作为 y 值\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "# 分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "workspace_dir = 'hw7_data/'\n",
    "start_time = time.time()\n",
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
    "print(\"Size of validation data = {}\".format(len(val_x)))\n",
    "test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
    "print(\"Size of Testing data = {}\".format(len(test_x)))\n",
    "end_time = time.time()\n",
    "print(\"用时：\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 来自torchvision.transforms\n",
    "# 训练数据做数据增强 (data augmentation)\n",
    "train_transform = transforms.Compose([ # 处理图片, 用Compose把多个处理步骤整合到一起\n",
    "    #transforms.ToPILImage(), #把数据转换为tensfroms格式\n",
    "    transforms.RandomCrop(256, pad_if_needed = True, padding_mode='symmetric'), # 随机裁剪到256*256\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片左右镜像\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] ,这个格式可以直接输入进神经网络了\n",
    "])\n",
    "\n",
    "# 测试数据不需做 数据增强 (data augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),   \n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 定义ImgDataset类，继承torch.utils.data.Dataset，实现数据读取方式\n",
    "# torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,...) \n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None: #将 y 变成一个长向量 64-bit integer (signed)\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index): #取一张图片和对应的分类 y 值\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None: # 判断是否需要 y 值\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "train_set = ImgDataset(train_x, train_y, train_transform) #训练集\n",
    "val_set = ImgDataset(val_x, val_y, test_transform) #验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 使用torch.utils.data.DataLoader(), 实现数据的批量读取\n",
    "#dataset：加载的数据集(Dataset对象); batch_size：batch size; shuffle:：是否将数据打乱\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型\n",
    "载入提供的模型，设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net = models.resnet18(pretrained = False, num_classes=11).cuda()\n",
    "student_net = Architecture_Design.StudentNet(base=16).cuda()\n",
    "\n",
    "teacher_net.load_state_dict(torch.load('hw7_data/teacher_resnet18.bin'))\n",
    "optimizer = optim.AdamW(student_net.parameters(), lr = 0.001)\n",
    "\n",
    "def loss_fn_kd(outputs, labels, teacher_outputs, T = 20, alpha = 0.5):\n",
    "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha) # 一般的Cross Entropy\n",
    "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) \n",
    "    return hard_loss + soft_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training\n",
    "- 剩下的步驟與你在做hw3 - CNN的時候一樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1轮 : [train loss: 0.6292, acc: 0.1590] [valid loss: 0.8030, acc: 0.1300], 用时：7.54 sec(s)\n",
      "第 2轮 : [train loss: 0.5840, acc: 0.2670] [valid loss: 0.7957, acc: 0.2520], 用时：7.51 sec(s)\n",
      "第 3轮 : [train loss: 0.5687, acc: 0.2740] [valid loss: 0.5888, acc: 0.3220], 用时：7.52 sec(s)\n",
      "第 4轮 : [train loss: 0.5453, acc: 0.3120] [valid loss: 0.6964, acc: 0.2880], 用时：7.54 sec(s)\n",
      "第 5轮 : [train loss: 0.5368, acc: 0.3420] [valid loss: 0.5780, acc: 0.3780], 用时：7.50 sec(s)\n",
      "第 6轮 : [train loss: 0.5206, acc: 0.3460] [valid loss: 0.5602, acc: 0.3820], 用时：7.53 sec(s)\n",
      "第 7轮 : [train loss: 0.5367, acc: 0.3520] [valid loss: 0.5735, acc: 0.3460], 用时：7.53 sec(s)\n",
      "第 8轮 : [train loss: 0.5116, acc: 0.3500] [valid loss: 0.5265, acc: 0.4220], 用时：7.54 sec(s)\n",
      "第 9轮 : [train loss: 0.5034, acc: 0.3980] [valid loss: 0.5488, acc: 0.3660], 用时：7.56 sec(s)\n",
      "第10轮 : [train loss: 0.4801, acc: 0.4010] [valid loss: 0.5131, acc: 0.4060], 用时：7.54 sec(s)\n",
      "第11轮 : [train loss: 0.4737, acc: 0.4130] [valid loss: 0.5150, acc: 0.4160], 用时：7.56 sec(s)\n",
      "第12轮 : [train loss: 0.4736, acc: 0.4210] [valid loss: 0.5243, acc: 0.4060], 用时：7.54 sec(s)\n",
      "第13轮 : [train loss: 0.4815, acc: 0.4020] [valid loss: 0.5372, acc: 0.3900], 用时：7.53 sec(s)\n",
      "第14轮 : [train loss: 0.4695, acc: 0.4410] [valid loss: 0.6008, acc: 0.3840], 用时：7.55 sec(s)\n",
      "第15轮 : [train loss: 0.4686, acc: 0.4420] [valid loss: 0.5061, acc: 0.4340], 用时：7.55 sec(s)\n",
      "第16轮 : [train loss: 0.4700, acc: 0.4580] [valid loss: 0.5107, acc: 0.4280], 用时：7.56 sec(s)\n",
      "第17轮 : [train loss: 0.4556, acc: 0.4610] [valid loss: 0.5363, acc: 0.4220], 用时：7.58 sec(s)\n",
      "第18轮 : [train loss: 0.4532, acc: 0.4550] [valid loss: 0.5332, acc: 0.3900], 用时：7.60 sec(s)\n",
      "第19轮 : [train loss: 0.4292, acc: 0.4720] [valid loss: 0.5913, acc: 0.4060], 用时：7.67 sec(s)\n",
      "第20轮 : [train loss: 0.4165, acc: 0.4760] [valid loss: 0.4913, acc: 0.4280], 用时：7.58 sec(s)\n",
      "第21轮 : [train loss: 0.4162, acc: 0.5030] [valid loss: 0.5116, acc: 0.4120], 用时：7.60 sec(s)\n",
      "第22轮 : [train loss: 0.4173, acc: 0.5150] [valid loss: 0.5273, acc: 0.4160], 用时：7.59 sec(s)\n",
      "第23轮 : [train loss: 0.4002, acc: 0.5260] [valid loss: 0.5868, acc: 0.4280], 用时：7.57 sec(s)\n",
      "第24轮 : [train loss: 0.3903, acc: 0.5270] [valid loss: 0.4973, acc: 0.4640], 用时：7.60 sec(s)\n",
      "第25轮 : [train loss: 0.3794, acc: 0.5210] [valid loss: 0.4743, acc: 0.4640], 用时：7.67 sec(s)\n",
      "第26轮 : [train loss: 0.3707, acc: 0.5340] [valid loss: 0.6807, acc: 0.4160], 用时：7.58 sec(s)\n",
      "第27轮 : [train loss: 0.3954, acc: 0.5320] [valid loss: 0.4643, acc: 0.4700], 用时：7.58 sec(s)\n",
      "第28轮 : [train loss: 0.3716, acc: 0.5590] [valid loss: 0.5511, acc: 0.4200], 用时：7.58 sec(s)\n",
      "第29轮 : [train loss: 0.3783, acc: 0.5470] [valid loss: 0.5103, acc: 0.4560], 用时：7.55 sec(s)\n",
      "第30轮 : [train loss: 0.3497, acc: 0.5670] [valid loss: 0.5241, acc: 0.4260], 用时：7.58 sec(s)\n",
      "第31轮 : [train loss: 0.3591, acc: 0.5800] [valid loss: 0.4119, acc: 0.5320], 用时：7.61 sec(s)\n",
      "第32轮 : [train loss: 0.3426, acc: 0.5760] [valid loss: 0.4899, acc: 0.4680], 用时：7.56 sec(s)\n",
      "第33轮 : [train loss: 0.3466, acc: 0.5860] [valid loss: 0.4456, acc: 0.4900], 用时：7.58 sec(s)\n",
      "第34轮 : [train loss: 0.3356, acc: 0.5990] [valid loss: 0.4444, acc: 0.5080], 用时：7.57 sec(s)\n",
      "第35轮 : [train loss: 0.3488, acc: 0.6040] [valid loss: 0.4815, acc: 0.4820], 用时：7.59 sec(s)\n",
      "第36轮 : [train loss: 0.3433, acc: 0.5900] [valid loss: 0.4456, acc: 0.5000], 用时：7.58 sec(s)\n",
      "第37轮 : [train loss: 0.3308, acc: 0.5770] [valid loss: 0.4335, acc: 0.5140], 用时：7.57 sec(s)\n",
      "第38轮 : [train loss: 0.3330, acc: 0.6070] [valid loss: 0.4615, acc: 0.4820], 用时：7.56 sec(s)\n",
      "第39轮 : [train loss: 0.3246, acc: 0.5930] [valid loss: 0.4773, acc: 0.4880], 用时：7.65 sec(s)\n",
      "第40轮 : [train loss: 0.3265, acc: 0.6190] [valid loss: 0.4365, acc: 0.5100], 用时：7.60 sec(s)\n",
      "第41轮 : [train loss: 0.3111, acc: 0.6310] [valid loss: 0.4341, acc: 0.5140], 用时：7.64 sec(s)\n",
      "第42轮 : [train loss: 0.3088, acc: 0.6490] [valid loss: 0.4305, acc: 0.4760], 用时：7.59 sec(s)\n",
      "第43轮 : [train loss: 0.3060, acc: 0.6440] [valid loss: 0.4292, acc: 0.4820], 用时：7.57 sec(s)\n",
      "第44轮 : [train loss: 0.2947, acc: 0.6530] [valid loss: 0.4601, acc: 0.4900], 用时：7.59 sec(s)\n",
      "第45轮 : [train loss: 0.3148, acc: 0.6390] [valid loss: 0.4751, acc: 0.4880], 用时：7.58 sec(s)\n",
      "第46轮 : [train loss: 0.2999, acc: 0.6420] [valid loss: 0.4698, acc: 0.5080], 用时：7.57 sec(s)\n",
      "第47轮 : [train loss: 0.2869, acc: 0.6410] [valid loss: 0.4158, acc: 0.5260], 用时：7.59 sec(s)\n",
      "第48轮 : [train loss: 0.2992, acc: 0.6370] [valid loss: 0.4326, acc: 0.5140], 用时：7.57 sec(s)\n",
      "第49轮 : [train loss: 0.2840, acc: 0.6720] [valid loss: 0.4399, acc: 0.5280], 用时：7.60 sec(s)\n",
      "第50轮 : [train loss: 0.2902, acc: 0.6600] [valid loss: 0.4184, acc: 0.4840], 用时：7.67 sec(s)\n",
      "第51轮 : [train loss: 0.2707, acc: 0.6860] [valid loss: 0.4624, acc: 0.4920], 用时：7.65 sec(s)\n",
      "第52轮 : [train loss: 0.2823, acc: 0.7050] [valid loss: 0.4270, acc: 0.4960], 用时：7.65 sec(s)\n",
      "第53轮 : [train loss: 0.2688, acc: 0.6750] [valid loss: 0.4702, acc: 0.4780], 用时：7.63 sec(s)\n",
      "第54轮 : [train loss: 0.2709, acc: 0.7040] [valid loss: 0.4058, acc: 0.5360], 用时：7.60 sec(s)\n",
      "第55轮 : [train loss: 0.2755, acc: 0.6810] [valid loss: 0.4303, acc: 0.5200], 用时：7.59 sec(s)\n",
      "第56轮 : [train loss: 0.2662, acc: 0.6900] [valid loss: 0.4610, acc: 0.4780], 用时：7.62 sec(s)\n",
      "第57轮 : [train loss: 0.2742, acc: 0.6760] [valid loss: 0.4625, acc: 0.5400], 用时：7.60 sec(s)\n",
      "第58轮 : [train loss: 0.2729, acc: 0.6850] [valid loss: 0.4171, acc: 0.5380], 用时：7.62 sec(s)\n",
      "第59轮 : [train loss: 0.2679, acc: 0.7010] [valid loss: 0.4538, acc: 0.5200], 用时：7.59 sec(s)\n",
      "第60轮 : [train loss: 0.2521, acc: 0.7030] [valid loss: 0.4128, acc: 0.5080], 用时：7.59 sec(s)\n",
      "第61轮 : [train loss: 0.2543, acc: 0.7160] [valid loss: 0.4837, acc: 0.5120], 用时：7.57 sec(s)\n",
      "第62轮 : [train loss: 0.2618, acc: 0.7130] [valid loss: 0.4126, acc: 0.5420], 用时：7.62 sec(s)\n",
      "第63轮 : [train loss: 0.2496, acc: 0.7270] [valid loss: 0.5347, acc: 0.4820], 用时：7.60 sec(s)\n",
      "第64轮 : [train loss: 0.2628, acc: 0.7140] [valid loss: 0.4230, acc: 0.5480], 用时：7.61 sec(s)\n",
      "第65轮 : [train loss: 0.2460, acc: 0.7300] [valid loss: 0.4111, acc: 0.5220], 用时：7.57 sec(s)\n",
      "第66轮 : [train loss: 0.2503, acc: 0.7320] [valid loss: 0.4350, acc: 0.5120], 用时：7.59 sec(s)\n",
      "第67轮 : [train loss: 0.2571, acc: 0.7150] [valid loss: 0.4326, acc: 0.5220], 用时：7.61 sec(s)\n",
      "第68轮 : [train loss: 0.2524, acc: 0.7200] [valid loss: 0.4156, acc: 0.5480], 用时：7.59 sec(s)\n",
      "第69轮 : [train loss: 0.2413, acc: 0.7500] [valid loss: 0.4799, acc: 0.5100], 用时：7.59 sec(s)\n",
      "第70轮 : [train loss: 0.2417, acc: 0.7440] [valid loss: 0.4307, acc: 0.5220], 用时：7.59 sec(s)\n",
      "第71轮 : [train loss: 0.2585, acc: 0.7040] [valid loss: 0.4808, acc: 0.5200], 用时：7.62 sec(s)\n",
      "第72轮 : [train loss: 0.2477, acc: 0.7420] [valid loss: 0.4591, acc: 0.5160], 用时：7.62 sec(s)\n",
      "第73轮 : [train loss: 0.2325, acc: 0.7340] [valid loss: 0.4678, acc: 0.5100], 用时：7.59 sec(s)\n",
      "第74轮 : [train loss: 0.2441, acc: 0.7270] [valid loss: 0.4051, acc: 0.5160], 用时：7.61 sec(s)\n",
      "第75轮 : [train loss: 0.2228, acc: 0.7770] [valid loss: 0.3754, acc: 0.5500], 用时：7.58 sec(s)\n",
      "第76轮 : [train loss: 0.2210, acc: 0.7770] [valid loss: 0.4108, acc: 0.5440], 用时：7.60 sec(s)\n",
      "第77轮 : [train loss: 0.2362, acc: 0.7700] [valid loss: 0.4348, acc: 0.5240], 用时：7.60 sec(s)\n",
      "第78轮 : [train loss: 0.2383, acc: 0.7470] [valid loss: 0.3957, acc: 0.5700], 用时：7.62 sec(s)\n",
      "第79轮 : [train loss: 0.2246, acc: 0.7670] [valid loss: 0.4140, acc: 0.5220], 用时：7.64 sec(s)\n",
      "第80轮 : [train loss: 0.2227, acc: 0.7530] [valid loss: 0.3938, acc: 0.5600], 用时：7.61 sec(s)\n",
      "第81轮 : [train loss: 0.2168, acc: 0.7780] [valid loss: 0.3991, acc: 0.5680], 用时：7.59 sec(s)\n",
      "第82轮 : [train loss: 0.2093, acc: 0.7780] [valid loss: 0.4109, acc: 0.5500], 用时：7.62 sec(s)\n",
      "第83轮 : [train loss: 0.2175, acc: 0.8070] [valid loss: 0.3921, acc: 0.5500], 用时：7.59 sec(s)\n",
      "第84轮 : [train loss: 0.2142, acc: 0.7740] [valid loss: 0.4327, acc: 0.5360], 用时：7.62 sec(s)\n",
      "第85轮 : [train loss: 0.2234, acc: 0.7600] [valid loss: 0.3827, acc: 0.5560], 用时：7.60 sec(s)\n",
      "第86轮 : [train loss: 0.2137, acc: 0.8020] [valid loss: 0.4065, acc: 0.5540], 用时：7.59 sec(s)\n",
      "第87轮 : [train loss: 0.2084, acc: 0.8190] [valid loss: 0.3939, acc: 0.5380], 用时：7.60 sec(s)\n",
      "第88轮 : [train loss: 0.2223, acc: 0.7730] [valid loss: 0.3737, acc: 0.5620], 用时：7.63 sec(s)\n",
      "第89轮 : [train loss: 0.2132, acc: 0.7850] [valid loss: 0.3930, acc: 0.5720], 用时：7.64 sec(s)\n",
      "第90轮 : [train loss: 0.2082, acc: 0.8060] [valid loss: 0.4403, acc: 0.5040], 用时：7.59 sec(s)\n",
      "第91轮 : [train loss: 0.2103, acc: 0.7870] [valid loss: 0.3792, acc: 0.5840], 用时：7.60 sec(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第92轮 : [train loss: 0.2043, acc: 0.7920] [valid loss: 0.4194, acc: 0.5620], 用时：7.59 sec(s)\n",
      "第93轮 : [train loss: 0.2080, acc: 0.7900] [valid loss: 0.4097, acc: 0.5400], 用时：7.60 sec(s)\n",
      "第94轮 : [train loss: 0.2073, acc: 0.8030] [valid loss: 0.4083, acc: 0.5440], 用时：7.60 sec(s)\n",
      "第95轮 : [train loss: 0.2073, acc: 0.8030] [valid loss: 0.4041, acc: 0.5640], 用时：7.57 sec(s)\n",
      "第96轮 : [train loss: 0.1932, acc: 0.8390] [valid loss: 0.4202, acc: 0.5560], 用时：7.63 sec(s)\n",
      "第97轮 : [train loss: 0.1907, acc: 0.8100] [valid loss: 0.3994, acc: 0.5460], 用时：7.60 sec(s)\n",
      "第98轮 : [train loss: 0.2039, acc: 0.7880] [valid loss: 0.3891, acc: 0.5900], 用时：7.61 sec(s)\n",
      "第99轮 : [train loss: 0.2039, acc: 0.8200] [valid loss: 0.4519, acc: 0.5240], 用时：7.60 sec(s)\n",
      "第100轮 : [train loss: 0.1802, acc: 0.8450] [valid loss: 0.3791, acc: 0.5640], 用时：7.60 sec(s)\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(train_loader, alpha=0.5):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    for i, data in enumerate(train_loader): # 给train_loader的矩阵一个编号，并组合成一个表\n",
    "        optimizer.zero_grad() # 將 model 參數的 gradient 歸零\n",
    "        with torch.no_grad(): # 先用 teacher_net 算一次\n",
    "            soft_labels = teacher_net(data[0].cuda()) \n",
    "        train_pred = student_net(data[0].cuda()) # 再用 student_net 算一次\n",
    "        \n",
    "        loss = loss_fn_kd(train_pred, data[1].cuda(), soft_labels, 20, alpha) #算 student_net 和  teacher_net 的差\n",
    "        loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += loss.item()\n",
    "    return train_loss/train_set.__len__(), train_acc/train_set.__len__()\n",
    "\n",
    "def val_epoch(val_loader, alpha=0.5):\n",
    "    val_acc, val_loss = 0 ,0\n",
    "    with torch.no_grad(): #torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度\n",
    "        for i, data in enumerate(val_loader):\n",
    "            with torch.no_grad(): # 先用 teacher_net 算一次\n",
    "                soft_labels = teacher_net(data[0].cuda()) \n",
    "            with torch.no_grad(): # 再用 student_net 算一次\n",
    "                val_pred = student_net(data[0].cuda())\n",
    "                loss = loss_fn_kd(val_pred, data[1].cuda(), soft_labels, 20, alpha) #算 student_net 和  teacher_net 的差\n",
    "            \n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += loss.item()\n",
    "    return val_loss/val_set.__len__(), val_acc/val_set.__len__()\n",
    "\n",
    "\n",
    "teacher_net.eval() # TeacherNet永遠都是Eval mode\n",
    "now_best_acc = 0\n",
    "for epoch in range(100):\n",
    "    epoch_start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = train_epoch(train_loader)\n",
    "    student_net.eval()\n",
    "    valid_loss, valid_acc = val_epoch(val_loader)\n",
    "\n",
    "    # 存下最好的model。\n",
    "    if valid_acc > now_best_acc:\n",
    "        now_best_acc = valid_acc\n",
    "        torch.save(student_net.state_dict(), 'hw7_data/student_model_Knowledge_Distillation.bin')\n",
    "    print('第{:>3d}轮 : [train loss: {:6.4f}, acc: {:6.4f}] [valid loss: {:6.4f}, acc: {:6.4f}], 用时：{:4.2f} sec(s)'.format(\n",
    "            epoch+1, train_loss, train_acc, valid_loss, valid_acc, time.time()-epoch_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImgDataset(test_x, transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False)\n",
    "name = ['面包', '奶', '甜品', '蛋', '油炸食品', '肉', '面条', '米饭', '海鲜', '汤', '果蔬']\n",
    "prediction = []\n",
    "\n",
    "student_net = Architecture_Design.StudentNet(base=16).cuda()\n",
    "student_net.load_state_dict(torch.load('hw7_data/student_model_Knowledge_Distillation.bin'))\n",
    "student_net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        test_pred = student_net(data.cuda())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)\n",
    "        \n",
    "def rename_and_write_csv():\n",
    "    f = os.listdir(\"hw7_data/testing_prediction\")\n",
    "    for i in range(len(f)):\n",
    "        oldname = f[i]\n",
    "        newname = oldname.split(\".\")[0] + '-'+ name[prediction[i]] + '.jpg'\n",
    "        # 用os模块中的rename方法对文件改名\n",
    "        os.rename(\"hw7_data/testing_prediction/\" + oldname, \"hw7_data/testing_prediction/\" + newname)\n",
    "    \n",
    "    #將結果寫入 csv 檔\n",
    "    with open(\"hw7_data/预测.csv\", 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        for i, y in  enumerate(prediction):\n",
    "            f.write('{},{},{}\\n'.format(i, y, name[y]))\n",
    "        \n",
    "#rename_and_write_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
